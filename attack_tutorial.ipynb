{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SecML Malware Tutorial\n",
    "\n",
    "In this tutorial, you will learn how to use this plugin to test the already implemented attacks against a PyTorch network of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-08 15:12:00,494 - py.warnings - WARNING - /opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import magic\n",
    "import secml_malware\n",
    "from secml.array import CArray\n",
    "from secml_malware.models.malconv import MalConv\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel\n",
    "\n",
    "net = MalConv()\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "net.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we have created the network (MalConv) and it has been passed wrapped with a *CClassifierEnd2EndMalware* model class.\n",
    "This object generalizes PyTorch end-to-end ML models.\n",
    "Since MalConv is already coded inside the plugin, the weights are also stored, and they can be retrieved with the *load_pretrained_model* method.\n",
    "\n",
    "If you wish to use diffierent weights, pass the path to the PyTorch *pth* file to that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
       "  (embedding_1): Embedding(257, 8)\n",
       "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': 'binary_crossentropy', 'optimizer': None, 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml_malware.attack.whitebox.c_header_evasion import CHeaderEvasion\n",
    "\n",
    "partial_dos = CHeaderEvasion(net, random_init=False, iterations=50, optimize_all_dos=False, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHeaderEvasion{'classifier': CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
       "  (embedding_1): Embedding(257, 8)\n",
       "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': 'binary_crossentropy', 'optimizer': None, 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, 'x_opt': None, 'f_opt': None, 'x_seq': None, 'f_seq': None, 'attack_classes': 'all', 'y_target': CClassifierEnd2EndMalware{'classes': array([0, 1]), 'n_features': 1048576, 'preprocess': None, 'n_jobs': 1, 'model': MalConv(\n",
       "  (embedding_1): Embedding(257, 8)\n",
       "  (conv1d_1): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (conv1d_2): Conv1d(8, 128, kernel_size=(500,), stride=(500,))\n",
       "  (dense_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dense_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "), 'trained': False, 'input_shape': (1, 1048576), 'softmax_outputs': False, 'batch_size': 256, 'loss': 'binary_crossentropy', 'optimizer': None, 'optimizer_scheduler': None, 'epochs': 100, 'plus_version': False, 'train_transform': Lambda()}, 'iterations': 50, 'is_debug': False, 'indexes_to_perturb': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], 'confidences_': [], 'changes_per_iterations_': [], 'random_init': False, 'embedding_size': 8, 'max_input_length': 1048576, 'invalid_pos': 256, 'embedding_value': 256, 'shift_values': False, 'threshold': 0.5, 'penalty_regularizer': 0, 'store_checkpoints': None, 'chunk_hyper_parameter': 256, 'optimize_all_dos': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_dos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how an attack is created, no further action is needed.\n",
    "The `random_init` parameter specifies if the bytes should be assigned with random values before beginning the optimization process, `iterations` sets the number of steps of the attack, `optimize_all_dos` sets if all the DOS header should be perturbed, or just the first 58 bytes, while `threshold` is the detection threshold used as a stopping condition.\n",
    "\n",
    "If you want to see how much the network is deteriorated by the attack, set this parameter to 0, or it will stop as soon as the confidence decreases below such value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"secml_malware/data/malware_samples/test_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'secml_malware/data/malware_samples/test_folder'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Added Backdoor.Win32.Agent.bhwo_ee98.exe with confidence 0.0026014018803834915\n",
      "> Added 0A32eTdBKayjCWhZqDOQ.exe with confidence 6.77412708682823e-06\n",
      "> Added .DS_Store with confidence 3.8153333270507517e-10\n",
      "> Added Backdoor.Win32.Agent.aiaq_a322.exe with confidence 0.18477359414100647\n",
      "> Added Backdoor.Win32.Agent.bflv_ce22.exe with confidence 0.997641921043396\n",
      "> Added 0ACDbR5M3ZhBJajygTuf.exe with confidence 0.0009867370827123523\n",
      "> Added Backdoor.Win32.Agent.azke_ae4f.exe with confidence 1.1902972119059996e-07\n",
      "> Added Backdoor.Win32.Agent.afxs_ed7c.exe with confidence 0.12736032903194427\n"
     ]
    }
   ],
   "source": [
    "folder = \"secml_malware/data/malware_samples/test_folder\"\n",
    "X = []\n",
    "y = []\n",
    "file_names = []\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    path = os.path.join(folder, f)\n",
    "    #if \"PE32\" not in magic.from_file(path):\n",
    "        #continue\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    x = End2EndModel.bytes_to_numpy(\n",
    "        code, net.get_input_max_length(), 256, False\n",
    "    )\n",
    "    _, confidence = net.predict(CArray(x), True)\n",
    "\n",
    "    #if confidence[0, 1].item() < 0.5:\n",
    "        #continue\n",
    "\n",
    "    print(f\"> Added {f} with confidence {confidence[0,1].item()}\")\n",
    "    X.append(x)\n",
    "    conf = confidence[1][0].item()\n",
    "    y.append([1 - conf, conf])\n",
    "    file_names.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a simple dataset from the `malware_samples/test_folder` that you have filled with malware to test the attacks.\n",
    "We discard all the samples that are not seen by the network.\n",
    "The `CArray` class is the base object you will handle when dealing with vectors in this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-08 15:52:07,104 - py.warnings - WARNING - /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py:214: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "\n",
      "2021-05-08 15:52:07,106 - py.warnings - WARNING - /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py:215: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(*args, **kwargs)\n",
      "\n",
      "Stopped at confidence below threshold: 0.005095718894153833/0.5\n",
      "[0.997641921043396, 0.005095718894153833]\n",
      "0.005095718894153833\n"
     ]
    }
   ],
   "source": [
    "for sample, label in zip(X, y):\n",
    "    y_pred, adv_score, adv_ds, f_obj = partial_dos.run(CArray(sample), CArray(label[1]))\n",
    "    print(partial_dos.confidences_)\n",
    "    print(f_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `adv_ds` object, you can find the adversarial example computed by the attack.\n",
    "You can reconstruct the functioning example by using a specific function inside the plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CArray(1, 1048576)(dense: [[ 77.  90. 159. ... 256. 256. 256.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_ds.X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secml.data.c_dataset.CDataset"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adv_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8704\n",
      "0.005095718894153833\n"
     ]
    }
   ],
   "source": [
    "adv_x = adv_ds.X[0,:]\n",
    "real_adv_x = partial_dos.create_real_sample_from_adv(file_names[0], adv_x)\n",
    "print(len(real_adv_x))\n",
    "real_x = End2EndModel.bytes_to_numpy(real_adv_x, net.get_input_max_length(), 256, False)\n",
    "_, confidence = net.predict(CArray(real_x), True)\n",
    "print(confidence[0,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and you're done!\n",
    "If you want to create a real sample (stored on disk), just have a look at the `create_real_sample_from_adv` of each attack. It accepts a third string argument that will be used as a destination file path for storing the adversarial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
